$ ... is the shell command used
// ... is the explanation/output of the above shell command

$ sort -o words /usr/share/dict/words
//create a file called `words` with sorted content in /usr/share/dict/words
$ emacs text.txt
//create a file called text.txt, then copy the html link into this file
$man tr
//tr - translate or delete characters
  -c, -C, --complement: use the complement of SET1
$tr -c 'A-Za-z' '[\n*]' < text.txt
//output:
https


web
cs
ucla
edu
classes
fall


cs

L
assign
assign

html
//This command is to find characters that are not A-Z or a-z, and convert those characters into \n (a new line)
$ tr -cs 'A-Za-z' '[\n*]' < text.txt
//output:
https
web
cs
ucla
edu
classes
fall
cs
L
assign
assign
html
//This command is to replace a sequence of repeated characters that are not A-z or a-z with \n (a new line), because the -s command is used to squeeze repeats.
$ tr -cs 'A-Za-z' '[\n*]' < text.txt | sort
//output:
L
assign
assign
classes
cs
cs
edu
fall
html
https
ucla
web
//This command is to take the output of the previous command and sort them in alphabetical order with upper case letters in the front.
$ tr -cs 'A-Za-z' '[\n*]' < text.txt | sort -u
//output:
L
assign
classes
cs
edu
fall
html
https
ucla
web
//This command is to sort and eliminate repetitions, because -u is used to display only the unique result.
$ tr -cs 'A-Za-z' '[\n*]' < text.txt | sort -u | comm - words
//The output has three columns. The first column shows words appeared uniquely in the output file from previous question. The second column is a long list of sorted words from the words file I created before. The third column shows words that this two files have in common, because comm command is used to compare two files.
$ tr -cs 'A-Za-z' '[\n*]' < text.txt | sort -u | comm -23 - words
//output:
edu
html
https
ucla
//The output only prints lines unique to file 1 (the output generated by tr -cs 'A-Za-z' '[\n*]' < text.txt | sort -u), because -23 means to suppress the second and third column in the output of comm - words.

buildwords.sh
#!/bin/sh
sed -E 's/\?|<u>|<\/u>//g' | \
grep -oP "(?<=<td).*(?=<\/td>)" | \
sed -E 's/[^>]*>//' | \
sed "s/\`/\'/g" | \
tr A-Z a-z | \
sed "/[^pk'mnwlhaeiou ]/d" | \
sed "s/ /\n/g" | \
sed "/^$/d" | \
sort -u

Explain: First remove ?, <u>, and </u>. Then search all the lines begins with <td and ends with </td>, and grep the content betweens this two headers. Then delete the starting X> in each line (X contains no ‘>’ characters). Then convert ` into ', and all upper case into lower case. After that, remove all the lines contain non-hawaiian characters. Then replace space with a new line, and delete empty lines. At last, sort the remaining words.

Problems I encountered:
First I tried to use $ grep -oP "(?<=<td>).*(?=<\/td>)" to match all the words that exist between <td> and </td>. However, I then found out that sometimes the first <td> could include more things, like <tdxxxxx>, and my matching fails to take them into account. So I changed my matching to $ grep -oP "(?<=<td>).*(?=<\/td>)" then remove the starting characters and > in each line, using the command sed -E 's/[^>]*>//'.

$ cat assign2.html | tr -cs "pk\'mnwlhaeiou" '[\n*]' | tr A-Z a-z | sort -u | comm -23 - hwords > misH
$ wc -l misH
//output: 228 misH. This shows that according to my hwords checker, there are 228 mis-spelled Haiwaiian words
$ cat assign2.html | tr -cs 'A-Za-z' '[\n*]' | tr A-Z a-z| sort -u | comm -23 - words > misE
$ wc -l misE
//output: 49 misE. This shows that there are 49 mis-spelled English words.
$ comm -23 misE misH
//output: This shows words that are mis-spelled in English but not in Haiwaiian, such as hwnwdshw, lau, wiki
$ comm -13 misE misH
//output: This shows words that are mis-spelled in Haiwaiian but not in English such as open, home, keep



